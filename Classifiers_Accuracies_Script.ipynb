{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This script imports all necessary classifiers and modules. A setting dict is used to store parameters\n",
    "#and their initial values. \n",
    "# The setupAndRun function takes input X and y, and number of iterations to run classifiers on dataset\n",
    "#A dataframe for each dataset is returned to main script. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetakinger/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dictionary that holds parameters \n",
    "arr = [\n",
    "         {'n_neighbors': 2, 'algorithm': 'auto'},\n",
    "         {} ,\n",
    "        {},\n",
    "        {'C': 1.0, 'kernel':'linear'},\n",
    "        {},\n",
    "        {'n_estimators': 1000, 'max_depth': 10, 'max_features':'sqrt'},\n",
    "        #hidden layer sizes (increment by 10), n_estimators, learning rate (increment by 1 each iter)\n",
    "        {'hidden_layer_sizes': 150 , 'max_iter': 200},\n",
    "        {'base_estimator': RandomForestClassifier(), 'n_estimators': 1000, 'learning_rate': 1.0},\n",
    "        {'n_estimators': 1000, 'max_depth': 10, 'max_features': 'sqrt'}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['classifier name'] = ['KNN', 'Decision Tree', 'Naive Bayes', 'SVM', 'Gaussian Process', 'Random Forest', 'Neural Net', 'AdaBoost', 'Extra Trees Classifier']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def setupAndRun(dataset_name, X, y, num_iterations):\n",
    "    \n",
    "    for i in range(1, num_iterations):\n",
    "        name = dataset_name + str(i)\n",
    "        models = []\n",
    "        models.append(('KNN', KNeighborsClassifier(**arr[0])))\n",
    "        models.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "        models.append(('Naive Bayes', GaussianNB()))\n",
    "        models.append(('SVM', SVC(**arr[3])))\n",
    "        models.append(('Gaussian Process', GaussianProcessClassifier()))\n",
    "        models.append(('Random Forest', RandomForestClassifier(**arr[5])))\n",
    "        models.append(('Neural Net', MLPClassifier(**arr[6])))\n",
    "        models.append(('AdaBoost', AdaBoostClassifier(**arr[7])))\n",
    "        models.append(('Extra Trees Classifier', ExtraTreesClassifier(**arr[8])))\n",
    "       \n",
    "        run_dataset(name, X, y, models)\n",
    "        \n",
    "        #increment n_neighbors\n",
    "        arr[0]['n_neighbors']+=2\n",
    "        #increment n_estimators by 500\n",
    "        arr[7]['n_estimators']+=500\n",
    "        #increment hidden_layer_sizes\n",
    "        arr[6]['hidden_layer_sizes']+=100\n",
    "        #increment number of trees used in random forest\n",
    "        arr[5]['n_estimators'] += 500\n",
    "        #increment learning_rate\n",
    "        arr[7]['learning_rate'] += 1.0\n",
    "        \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_dataset(dataset_name, X, y, models):\n",
    "    iter_range = range(1,6)\n",
    "    average_accuracy = 0.0\n",
    "    \n",
    "    accuracy_list = []\n",
    "    for name, model in models:\n",
    "        #print(name)\n",
    "        for i in iter_range:\n",
    "            classifier = model\n",
    "            #print (model)\n",
    "            scores = cross_val_score(classifier, X, y, cv=10, scoring='roc_auc')\n",
    "            average_accuracy+=scores.mean()\n",
    "        accuracy_list.append((average_accuracy/(5.0)))\n",
    "        average_accuracy = 0.0\n",
    "        \n",
    "    se = pd.Series(accuracy_list)\n",
    "    df[dataset_name] = se.values\n",
    "   \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
